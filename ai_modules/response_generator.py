# response_generator.py
import time
import os
import random
import threading
from typing import Optional, Dict, Any, List, Callable, Literal, AsyncGenerator
import wave

# ----------------------------
# SAFE IMPORT/FALLBACK cho config_db
# ----------------------------
_FALLBACK_API_KEY = "MOCK_API_KEY"

try:
    from config_db import GEMINI_MODEL, TTS_MODE_DEFAULT, TTS_VOICE_NAME_DEFAULT, API_KEY
except ImportError:
    GEMINI_MODEL = "gemini-2.5-flash"
    TTS_MODE_DEFAULT = "MOCK"
    TTS_VOICE_NAME_DEFAULT = "vi"
    API_KEY = _FALLBACK_API_KEY

# Mock/Fallback gTTS
try:
    from gtts import gTTS
except ImportError:
    gTTS = None
    
# ======================================================
# Lá»šP TTS CÆ  Sá» VÃ€ MOCK
# ======================================================

class BaseTTS:
    """Lá»›p cÆ¡ sá»Ÿ cho cÃ¡c cÃ´ng cá»¥ Text-to-Speech (MOCK)."""
    def __init__(self, log_callback: Callable):
        self.log = log_callback
        self.is_ready = True
        
    def generate(self, text: str, output_path: str) -> Optional[str]:
        # Giáº£ láº­p táº¡o file WAV (chá»‰ dÃ¹ng cho cháº¿ Ä‘á»™ file-based)
        try:
            with wave.open(output_path, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(16000)
                # Giáº£ láº­p 1 giÃ¢y audio rá»—ng
                wf.writeframes(b'\x00\x00' * 16000) 
            self.log(f"ğŸµ [TTS Mock] ÄÃ£ táº¡o file audio giáº£ láº­p: {os.path.basename(output_path)}", "magenta")
            return output_path
        except Exception as e:
            self.log(f"âŒ [TTS Mock] Lá»—i táº¡o file audio giáº£ láº­p: {e}", "red")
            return None
        
    def synthesize_stream(self, text: str) -> AsyncGenerator[bytes, None]:
        """Giáº£ láº­p streaming audio bytes (chunked)."""
        async def mock_stream():
             # Giáº£ láº­p stream 3 chunks
             yield b'MOCK_AUDIO_CHUNK_1'
             yield b'MOCK_AUDIO_CHUNK_2'
             yield b'MOCK_AUDIO_CHUNK_3'
        return mock_stream()
        
class MockTTS(BaseTTS):
    """Sá»­ dá»¥ng BaseTTS Mock."""
    pass

# ======================================================
# RESPONSE GENERATOR
# ======================================================

class ResponseGenerator:
    """
    Táº¡o pháº£n há»“i, sá»­ dá»¥ng LLM hoáº·c rule-based.
    CÅ©ng quáº£n lÃ½ TTS Client.
    """
    # ğŸš¨ FIX: Äáº£m báº£o __init__ nháº­n Ä‘á»§ 6 tham sá»‘ cáº§n thiáº¿t
    def __init__(self, log_callback: Callable, config: Dict[str, Any], llm_mode: str, tts_mode: str, db_mode: str, api_key: str):
        self.log = log_callback
        self.config = config
        self.llm_mode = llm_mode
        self.tts_mode = tts_mode
        self.db_mode = db_mode
        
        # API Key cáº§n Ä‘Æ°á»£c lÆ°u trá»¯ an toÃ n, sá»­ dá»¥ng threading.local Ä‘á»ƒ há»— trá»£ Ä‘á»“ng thá»i.
        self.api_key_var = threading.local()
        self.api_key_var.value = api_key or API_KEY # Láº¥y tá»« tham sá»‘ hoáº·c config_db/fallback

        # Khá»Ÿi táº¡o TTS Client
        self._initialize_tts_client()


    def _initialize_tts_client(self):
        """Khá»Ÿi táº¡o TTS client dá»±a trÃªn self.tts_mode."""
        if self.tts_mode == "MOCK":
            self.tts_client = MockTTS(self.log)
        else:
            # á» Ä‘Ã¢y cÃ³ thá»ƒ tÃ­ch há»£p Google Cloud TTS/Gradio TTS hoáº·c cÃ¡c engine khÃ¡c.
            self.log(f"âš ï¸ [TTS] Cháº¿ Ä‘á»™ TTS '{self.tts_mode}' khÃ´ng Ä‘Æ°á»£c há»— trá»£, sá»­ dá»¥ng Mock TTS.", "yellow")
            self.tts_client = MockTTS(self.log)
            
        self.log(f"ğŸµ [TTS] TTS Client Ä‘Ã£ khá»Ÿi táº¡o thÃ nh cÃ´ng (Mode: {self.tts_mode}).", "magenta")


    # API cÃ´ng khai Ä‘á»ƒ láº¥y TTS client
    @property
    def tts_client(self):
        return self._tts_client

    @tts_client.setter
    def tts_client(self, client):
        self._tts_client = client


    def _generate_with_rules(self, intent: str) -> Optional[str]:
        """Táº¡o pháº£n há»“i dá»±a trÃªn rule-based config."""
        
        # TÃ¬m rule theo intent
        for rule in self.config.get("rules", []):
            if rule["intent"] == intent:
                responses = rule.get("responses", [rule.get("response")])
                if responses:
                    return random.choice(responses)
        
        # Rule fallback cho no_match
        if intent != "no_match":
            return self._generate_with_rules("no_match")
            
        return None

    def _generate_with_db_info(self, intent: str, db_result: Dict[str, Any]) -> Optional[str]:
        """Táº¡o pháº£n há»“i chi tiáº¿t dá»±a trÃªn káº¿t quáº£ DB."""
        customer_data = db_result.get("customer_data")
        product_data = db_result.get("product_data")

        if intent == "query_customer_info" and customer_data:
            return (
                f"ThÃ´ng tin khÃ¡ch hÃ ng: **{customer_data['customer_name']}**."
                f" Láº§n Ä‘áº·t hÃ ng gáº§n nháº¥t: {customer_data['last_order']}."
                f" Báº¡n cáº§n há»— trá»£ thÃªm vá» thÃ´ng tin nÃ y khÃ´ng?"
            )
        
        if intent == "query_product_info" and product_data:
            discount = product_data.get("discount")
            if discount and int(discount) > 0:
                 return (
                    f"Sáº£n pháº©m **{product_data['product_name']}** hiá»‡n cÃ³ giÃ¡ {product_data['price']}."
                    f" Báº¡n sáº½ Ä‘Æ°á»£c giáº£m giÃ¡ {discount} pháº§n trÄƒm. Báº¡n cÃ³ muá»‘n Ä‘áº·t hÃ ng ngay khÃ´ng?"
                 )
            else:
                 return (
                    f"Sáº£n pháº©m **{product_data['product_name']}** cÃ³ giÃ¡ {product_data['price']}. "
                    f"Hiá»‡n sáº£n pháº©m nÃ y khÃ´ng cÃ³ khuyáº¿n mÃ£i nÃ o Ä‘áº·c biá»‡t. "
                    f"Báº¡n cÃ³ muá»‘n tÃ´i kiá»ƒm tra thÃ´ng tin khÃ¡c khÃ´ng?"
                 )
        
        return None

    def _generate_with_llm_mock(self, llm_context: Dict[str, Any]) -> str:
        """Giáº£ láº­p táº¡o pháº£n há»“i ngÃ´n ngá»¯ tá»± nhiÃªn báº±ng LLM."""
        api_key = getattr(self.api_key_var, 'value', _FALLBACK_API_KEY)
        
        if not api_key or api_key == _FALLBACK_API_KEY:
            return f"TÃ´i Ä‘Ã£ nháº­n Ä‘Æ°á»£c yÃªu cáº§u (**{llm_context['intent']}**). Vui lÃ²ng cung cáº¥p API Key Ä‘á»ƒ sá»­ dá»¥ng trÃ­ tuá»‡ nhÃ¢n táº¡o táº¡o pháº£n há»“i chi tiáº¿t hÆ¡n."

        try:
            self.log(f"ğŸ—£ï¸ [GEMINI MOCK] Pháº£n há»“i Ä‘Ã£ nháº­n (Mock LLM) vá»›i API Key: {llm_context['intent']}", color="blue")
            db_info_str = ""
            if llm_context['db_result'].get("customer_data"): db_info_str += f" | KH: {llm_context['db_result']['customer_data']['customer_name']}"
            if llm_context['db_result'].get("product_data"): db_info_str += f" | SP: {llm_context['db_result']['product_data']['product_name']}"
            
            history_len = len(llm_context.get('history', []))
            
            return (
                 f"ÄÃ¢y lÃ  pháº£n há»“i LLM giáº£ láº­p cho yÃªu cáº§u: '**{llm_context['user_text']}**'. "
                 f"Tráº¡ng thÃ¡i hiá»‡n táº¡i: **{llm_context['current_state']}**."
                 f" (Dá»¯ liá»‡u ná»n: {db_info_str}). "
                 f"Lá»‹ch sá»­ há»™i thoáº¡i: **{history_len} lÆ°á»£t**."
            )
        except Exception as e:
            self.log(f"âŒ [GEMINI MOCK] Lá»—i táº¡o LLM Mock: {e}", "red")
            return "Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i khi táº¡o pháº£n há»“i LLM."
    

    def generate_response(
        self,
        user_text: str,
        intent: str,
        entities: Dict[str, Any],
        db_result: Dict[str, Any],
        current_state: str,
        history: List[Dict[str, str]] = [] # âœ… ThÃªm tham sá»‘ History
    ) -> str:
        """Táº¡o pháº£n há»“i cuá»‘i cÃ¹ng, Æ°u tiÃªn Rule -> DB -> LLM."""
        
        # 1. Rule-based / TÄ©nh
        response = self._generate_with_rules(intent)
        if response:
            return response

        # 2. DB-based / Chi tiáº¿t
        response = self._generate_with_db_info(intent, db_result)
        if response:
            return response
            
        # 3. LLM-based / NgÃ´n ngá»¯ tá»± nhiÃªn (hoáº·c Mock)
        llm_context = {
            "user_text": user_text,
            "intent": intent,
            "entities": entities,
            "db_result": db_result,
            "current_state": current_state,
            "history": history # Truyá»n History
        }
        return self._generate_with_llm_mock(llm_context)