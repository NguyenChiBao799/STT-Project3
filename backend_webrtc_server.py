import asyncio
import os
import json
import uuid
import wave
import numpy as np
import librosa  # ‚úÖ D√πng ƒë·ªÉ resample
import warnings
from typing import Dict, Any, Optional, Callable
from pathlib import Path
import traceback 
from fastapi import FastAPI, Request, UploadFile, File, Form
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from aiortc import RTCPeerConnection, RTCSessionDescription, MediaStreamTrack, RTCConfiguration, RTCIceServer
from aiortc.exceptions import InvalidStateError

# Routers
from routers import products, orders, promotions, payment

# WebRTC Pipeline
from ai_modules.rtc_integration_layer import RTCStreamProcessor, SAMPLE_RATE, INTERNAL_API_KEY

# === MODULES M·ªöI (NLU ‚Üí LOGIC ‚Üí DIALOG) ===
from core.logic_manager import LogicManager
from ai_modules.dialog_manager import DialogManager
from core.stt_log_parser import STTLogParser
from core.json_loader import JSONLogLoader

import base64
from gtts import gTTS

# ============================================================
# üîß FIX CHO L·ªñI "Transaction.__retry()" TRONG AIORTC/AIOICE
# ============================================================
import aioice
aioice.stun.TRANSACTION_RETRY_INTERVAL = 2.0
aioice.stun.TRANSACTION_MAX_RETRIES = 4

warnings.filterwarnings("ignore", category=RuntimeWarning, message="invalid state")
warnings.filterwarnings("ignore", category=RuntimeWarning, message="coroutine.*was never awaited")

# ============================================================
# C·∫§U H√åNH CHUNG
# ============================================================
CHANNELS = 1
SAMPLE_WIDTH = 2
os.makedirs("temp", exist_ok=True)

ICE_SERVERS = [
    {"urls": "stun:stun1.l.google.com:19302"},
    {"urls": "stun:stun2.l.google.com:19302"},
    {"urls": "stun:stun3.l.google.com:19302"},
]

processing_tasks: Dict[str, asyncio.Task] = {}

# ============================================================
# APP KH·ªûI T·∫†O
# ============================================================
app = FastAPI(title="STT Voice AI Backend (WebRTC + REST API)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(products.router, prefix="/api")
app.include_router(orders.router, prefix="/api")
app.include_router(promotions.router, prefix="/api")
app.include_router(payment.router, prefix="/api")


# ============================================================
# LOGGING CHU·∫®N HO√Å (D√ôNG CHO C·∫¢ LOGICMANAGER & DM)
# ============================================================
def log_info(message: str, color="white"):
    print(f"INFO:backend_webrtc_server:[{message}]")


# ============================================================
# üî• T√çCH H·ª¢P LOGIC MANAGER + DIALOG MANAGER (ƒê√É FIX)
# ============================================================
# L∆∞u √Ω: ƒê·∫∑t sau log_info ƒë·ªÉ tr√°nh l·ªói NameError
logic_manager = LogicManager(log_callback=log_info)
dialog_manager = DialogManager(log_callback=log_info)

# ============================================================
# UTILITIES
# ============================================================
def _write_wav_file_safe_helper(file_path_str: str, chunks: list[bytes], wav_params_tuple: tuple):
    with wave.open(file_path_str, 'wb') as wf:
        wf.setparams(wav_params_tuple)
        for chunk in chunks:
            wf.writeframes(chunk)
    log_info(f"[WAV Writer] ‚úÖ Ghi file th√†nh c√¥ng: {file_path_str}")

WAV_PARAMS = (CHANNELS, SAMPLE_WIDTH, SAMPLE_RATE, 0, 'NONE', 'not compressed')
# ============================================================
# H√ÄM X·ª¨ L√ù AUDIO SAU GHI ‚Äî ƒê√É S·ª¨A HO√ÄN TO√ÄN & T√çCH H·ª¢P MODULE M·ªöI
# ============================================================
async def _process_audio_and_respond(session_id, dm_processor, pc, data_channel, record_file, api_key):
    try:
        if not record_file or not os.path.exists(record_file):
            if data_channel:
                data_channel.send(json.dumps({
                    "type": "error",
                    "error": "Kh√¥ng c√≥ d·ªØ li·ªáu audio ho·∫∑c file kh√¥ng t·ªìn t·∫°i."
                }))
            log_info(f"[{session_id}] ‚ö†Ô∏è B·ªè qua: file audio None ho·∫∑c kh√¥ng t·ªìn t·∫°i.")
            return

        # ========================================================
        # 1) G·ª≠i file WAV v√†o pipeline WebRTC ‚Üí ASR ‚Üí User Text
        # ========================================================
        stream_generator = dm_processor.handle_rtc_session(
            record_file=Path(record_file),
            session_id=session_id,
            api_key=api_key
        )

        audio_chunks_binary = []
        last_user_text = ""
        text_data = {}

        # ========================================================
        # 2) ƒê·ªçc t·ª´ng frame t·ª´ pipeline RTC Stream Processor
        # ========================================================
        async for is_audio, data in stream_generator:

            # ----------------------------------------------------
            # AUDIO STREAM ‚Üí L∆∞u binary l·∫°i ƒë·ªÉ t·∫°o bot_audio
            # ----------------------------------------------------
            if is_audio:
                audio_chunks_binary.append(
                    base64.b64decode(data) if isinstance(data, str) else data
                )
                continue

            # ----------------------------------------------------
            # TEXT STREAM ‚Üí ƒê√¢y m·ªõi l√† user_text t·ª´ ASR
            # ----------------------------------------------------
            user_text = data.get("user_text", "").strip()
            last_user_text = user_text

            # ====================================================
            # 3) D√ôNG PARSER ‚Üí CHU·∫®N HO√Å D·ªÆ LI·ªÜU NLU
            # ====================================================
            parser = STTLogParser(log_callback=log_info)
            nlu_json = parser.convert({
                "text_response": {"user_text": user_text}
            })

            # ====================================================
            # 4) LOGIC MANAGER ‚Üí X√ÅC ƒê·ªäNH ACTION C·∫¶N L√ÄM
            # ====================================================
            decision = logic_manager.handle_nlu_result(nlu_json)

            # ====================================================
            # 5) DIALOG MANAGER ‚Üí T·∫†O PH·∫¢N H·ªíI HO√ÄN CH·ªàNH
            # ====================================================
            final_response = dialog_manager.process_with_logic_manager(
                nlu_json=nlu_json,
                logic_manager=logic_manager
            )

            bot_text = final_response.get("response_text") or final_response.get("text") or ""

            text_data = {
                "user_text": user_text,
                "bot_text": bot_text,
                "intent": decision.get("intent"),
                "action": decision.get("action"),
                "payment_url": decision.get("payment_url")
            }

            # ====================================================
            # 6) G·ª≠i ph·∫£n h·ªìi PARTIAL v·ªÅ WebRTC Client
            # ====================================================
            if data_channel:
                data_channel.send(json.dumps({"type": "text_response_partial", **text_data}))

        # ========================================================
        # 7) T·∫†O BOT AUDIO (WAV OUTPUT)
        # ========================================================
        output_file_name = f"{session_id}_output.wav"
        output_file_path = os.path.join("temp", output_file_name)

        if audio_chunks_binary:
            await asyncio.to_thread(
                _write_wav_file_safe_helper,
                output_file_path,
                audio_chunks_binary,
                WAV_PARAMS
            )
        else:
            # N·∫øu kh√¥ng c√≥ audio TTS t·ª´ DM ‚Üí d√πng gTTS fallback
            fallback_text = text_data.get("bot_text", "Xin l·ªói, t√¥i kh√¥ng nghe r√µ.")
            gTTS(fallback_text, lang="vi").save(output_file_path)

        # ========================================================
        # 8) GHI LOG JSON RA FILE
        # ========================================================
        response_json_path = os.path.join("temp", f"{session_id}_response.json")
        with open(response_json_path, "w", encoding="utf-8") as jf:
            json.dump({
                "session_id": session_id,
                "input_file": record_file,
                "output_audio": output_file_path,
                "text_response": text_data
            }, jf, ensure_ascii=False, indent=4)

        # ========================================================
        # 9) G·ª¨I END_OF_SESSION CHO WEBRTC CLIENT
        # ========================================================
        if data_channel:
            data_channel.send(json.dumps({
                "type": "end_of_session",
                "bot_audio_path": f"/audio_files/{output_file_name}"
            }))

        log_info(f"[{session_id}] ‚úÖ X·ª≠ l√Ω audio xong. Ph·∫£n h·ªìi g·ª≠i v·ªÅ client.")

    except Exception as e:
        log_info(f"[{session_id}] ‚ùå L·ªói x·ª≠ l√Ω audio: {e}")
        traceback.print_exc()
# ============================================================
# ENDPOINT /offer ‚Äî FULL CODE ƒê√É T√çCH H·ª¢P M·ªöI
# ============================================================
@app.post("/offer")
async def offer(request: Request):
    params = await request.json()

    # WebRTC Offer t·ª´ client
    offer = RTCSessionDescription(sdp=params["sdp"], type=params["type"])

    # Session ID t·ª´ client ho·∫∑c t·ª± sinh
    session_id = params.get("session_id", str(uuid.uuid4()))

    # API Key (b·∫±ng key n·ªôi b·ªô tr√™n backend)
    api_key = params.get("api_key", INTERNAL_API_KEY)

    # =======================
    # T·∫°o c·∫•u h√¨nh WebRTC ICE
    # =======================
    config = RTCConfiguration(
        iceServers=[RTCIceServer(urls=s["urls"]) for s in ICE_SERVERS]
    )
    pc = RTCPeerConnection(configuration=config)

    # Recorder ‚Äî nh·∫≠n track audio t·ª´ client
    recorder = AudioFileRecorder(pc)

    # DataChannel holder
    data_channel_holder = None

    # ==============================================================
    # Khi client m·ªü DataChannel ‚Üí gi·ªØ reference ƒë·ªÉ g·ª≠i text_response
    # ==============================================================
    @pc.on("datachannel")
    def on_datachannel(channel):
        nonlocal data_channel_holder
        data_channel_holder = channel
        log_info(f"[{session_id}] üì° DataChannel nh·∫≠n: {channel.label}")

        @channel.on("message")
        def on_message(message):
            try:
                data = json.loads(message)
                if data.get("type") == "stop_recording":
                    recorder.stop()
            except Exception as e:
                log_info(f"[{session_id}] ‚ùå L·ªói message handler: {e}")

    # ==============================================================
    # Khi client g·ª≠i audio track
    # ==============================================================
    @pc.on("track")
    def on_track(track):
        log_info(f"[{session_id}] üé§ Nh·∫≠n track audio: {track.kind}")

        if track.kind == "audio":
            path = os.path.join("temp", f"{session_id}_input.wav")

            # B·∫Øt ƒë·∫ßu ghi file WAV t·ª´ audio track
            recorder.start(track, path)

            # X·ª≠ l√Ω khi recorder d·ª´ng (g·ª≠i v√†o pipeline)
            recorder.on(
                "stop",
                lambda file_path: asyncio.create_task(
                    _process_audio_and_respond(
                        session_id=session_id,
                        dm_processor=RTCStreamProcessor(log_callback=log_info),
                        pc=pc,
                        data_channel=data_channel_holder,
                        record_file=file_path,
                        api_key=api_key
                    )
                )
            )

    # ==============================================================
    # SETUP OFFER ‚Äî TR·∫¢ ANSWER CHO CLIENT
    # ==============================================================
    await pc.setRemoteDescription(offer)
    answer = await pc.createAnswer()
    await pc.setLocalDescription(answer)

    return {
        "sdp": pc.localDescription.sdp,
        "type": pc.localDescription.type,
        "session_id": session_id
    }
# ============================================================
# üìÇ ENDPOINT: UPLOAD WAV FILE (D√ôNG CHO TEST & DEBUG)
# ============================================================
@app.post("/api/upload_wav")
async def upload_wav(file: UploadFile = File(...), api_key: str = Form(None)):
    """
    üìÇ Endpoint: T·∫£i file WAV l√™n backend ƒë·ªÉ ph√¢n t√≠ch:
    ‚Üí STT ‚Üí Parser ‚Üí LogicManager ‚Üí DialogManager ‚Üí Bot_text ‚Üí Bot_audio
    """
    try:
        os.makedirs("temp", exist_ok=True)
        session_id = str(uuid.uuid4())

        # --------------------------------------------------------
        # 1) L∆∞u file WAV ƒë∆∞·ª£c upload v√†o th∆∞ m·ª•c temp
        # --------------------------------------------------------
        temp_path = os.path.join("temp", f"{session_id}_uploaded.wav")
        with open(temp_path, "wb") as f:
            f.write(await file.read())

        log_info(f"[UPLOAD {session_id}] üìÅ File WAV nh·∫≠n: {file.filename} ‚Üí {temp_path}")

        # --------------------------------------------------------
        # 2) G·ª≠i file WAV v√†o pipeline WebRTC STT Processor
        # --------------------------------------------------------
        dm_processor = RTCStreamProcessor(log_callback=log_info)
        stream_gen = dm_processor.handle_rtc_session(
            record_file=Path(temp_path),
            session_id=session_id,
            api_key=api_key or INTERNAL_API_KEY,
        )

        last_user_text = ""
        audio_chunks_binary = []
        final_text_data = {}

        # --------------------------------------------------------
        # 3) ƒê·ªçc k·∫øt qu·∫£ STT & audio t·ª´ pipeline
        # --------------------------------------------------------
        async for is_audio, data in stream_gen:

            # AUDIO STREAM
            if is_audio:
                audio_chunks_binary.append(
                    base64.b64decode(data) if isinstance(data, str) else data
                )
                continue

            # TEXT STREAM
            user_text = data.get("user_text", "").strip()
            last_user_text = user_text

            # ----------------------------------------------------
            # 4) PARSER ‚Üí convert JSON STT ‚Üí JSON NLU chu·∫©n
            # ----------------------------------------------------
            parser = STTLogParser(log_callback=log_info)
            nlu_json = parser.convert({
                "text_response": {"user_text": user_text}
            })

            # ----------------------------------------------------
            # 5) LogicManager ‚Üí x√°c ƒë·ªãnh action & intent
            # ----------------------------------------------------
            decision = logic_manager.handle_nlu_result(nlu_json)

            # ----------------------------------------------------
            # 6) DialogManager ‚Üí t·∫°o bot_text
            # ----------------------------------------------------
            final_response = dialog_manager.process_with_logic_manager(
                nlu_json=nlu_json,
                logic_manager=logic_manager
            )

            bot_text = final_response.get("response_text") or final_response.get("text") or ""

            final_text_data = {
                "user_text": user_text,
                "bot_text": bot_text,
                "intent": decision.get("intent"),
                "action": decision.get("action"),
                "payment_url": decision.get("payment_url")
            }

        # --------------------------------------------------------
        # 7) GHI BOT AUDIO ‚Äî n·∫øu pipeline STT kh√¥ng tr·∫£ √¢m thanh
        # --------------------------------------------------------
        output_file = os.path.join("temp", f"{session_id}_output.wav")

        if audio_chunks_binary:
            await asyncio.to_thread(
                _write_wav_file_safe_helper,
                output_file,
                audio_chunks_binary,
                WAV_PARAMS
            )
        else:
            fallback_text = final_text_data.get("bot_text", "Xin l·ªói, t√¥i kh√¥ng nghe r√µ.")
            gTTS(fallback_text, lang="vi").save(output_file)

        # --------------------------------------------------------
        # 8) Chu·∫©n b·ªã JSON tr·∫£ v·ªÅ
        # --------------------------------------------------------
        response = {
            "session_id": session_id,
            "user_text": final_text_data.get("user_text", ""),
            "bot_text": final_text_data.get("bot_text", ""),
            "intent": final_text_data.get("intent", ""),
            "action": final_text_data.get("action", ""),
            "payment_url": final_text_data.get("payment_url", None),
            "bot_audio_path": f"/audio_files/{Path(output_file).name}" if os.path.exists(output_file) else None,
        }

        log_info(f"[UPLOAD {session_id}] üéØ K·∫øt qu·∫£: {response['bot_text']}")

        return JSONResponse(response)

    except Exception as e:
        log_info(f"[UPLOAD] ‚ùå L·ªói x·ª≠ l√Ω file WAV: {e}")
        traceback.print_exc()
        return JSONResponse({"error": str(e)}, status_code=500)
# ============================================================
# STATIC ROUTES ‚Äî SERVE AUDIO FILES & STATIC HTML
# ============================================================
# Th∆∞ m·ª•c temp ‚Üí ch·ª©a WAV input/output + JSON log
app.mount("/audio_files", StaticFiles(directory="temp"), name="audio_files")

# Th∆∞ m·ª•c static ‚Üí ch·ª©a QR payment, HTML demo UI
app.mount("/", StaticFiles(directory="static"), name="static")


# ============================================================
# MAIN ENTRY (CH·∫†Y B·∫∞NG PYTHON TR·ª∞C TI·∫æP)
# ============================================================
if __name__ == "__main__":
    import uvicorn
    log_info("üöÄ Backend WebRTC STT ƒëang kh·ªüi ƒë·ªông...")
    uvicorn.run(app, host="127.0.0.1", port=8000)
