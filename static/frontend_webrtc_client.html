<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice AI Assistant (WebRTC)</title>
  <style>
    body { font-family: Arial, sans-serif; background: #f4f6f9; margin: 0; padding: 20px; }
    .container { max-width: 860px; margin: auto; background: #fff; border-radius: 10px; padding: 20px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
    h1 { text-align: center; color: #333; margin-bottom: 10px; }
    .api-key-panel { background: #f8d7da; padding: 10px; border: 1px solid #f5c6cb; border-radius: 6px; }
    .control-panel { display: flex; justify-content: center; flex-wrap: wrap; gap: 15px; margin-top: 20px; }
    button { padding: 12px 24px; border-radius: 5px; border: none; font-size: 16px; cursor: pointer; }
    #startBtn { background: #28a745; color: white; }
    #stopBtn, #cancelBtn { background: #dc3545; color: white; }
    #uploadBtn { background: #007bff; color: white; }
    #status { text-align: center; margin-top: 15px; font-weight: bold; color: #007bff; }
    progress { width: 100%; height: 20px; margin-top: 8px; }
    .result-panel { margin-top: 20px; background: #fafafa; border: 1px solid #ddd; padding: 15px; border-radius: 6px; }
    .user-text { color: #333; margin-top: 10px; }
    .bot-text { color: #007bff; font-weight: bold; margin-top: 8px; }
    audio { width: 100%; margin-top: 10px; }
    #log { background: #f1f3f5; border-radius: 6px; padding: 10px; height: 200px; overflow-y: auto; font-size: 0.9em; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è Voice AI Assistant</h1>
    <div class="api-key-panel">
      <label for="apiKeyInput">üîê API Key: </label>
      <input id="apiKeyInput" type="text" placeholder="Nh·∫≠p API Key (t√πy ch·ªçn)" style="width:100%;">
    </div>

    <div class="control-panel">
      <button id="startBtn" disabled>üé§ Ghi √Çm</button>
      <button id="stopBtn" disabled>‚èπÔ∏è D·ª´ng</button>
      <button id="uploadBtn">üìÇ T·∫£i file WAV</button>
      <input type="file" id="fileInput" accept=".wav" style="display:none;">
      <button id="cancelBtn">‚ùå H·ªßy</button>
    </div>

    <div id="status">ƒêang kh·ªüi t·∫°o...</div>
    <progress id="progressBar" value="0" max="100"></progress>

    <div class="result-panel">
      <div id="textOutput">
        <div class="user-text"><strong>Ng∆∞·ªùi d√πng:</strong></div>
        <div class="bot-text"><strong>Bot:</strong></div>
      </div>
      <audio id="ttsAudio" controls autoplay></audio>
      <div id="log"></div>
    </div>
  </div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const uploadBtn = document.getElementById('uploadBtn');
    const fileInput = document.getElementById('fileInput');
    const cancelBtn = document.getElementById('cancelBtn');
    const statusDiv = document.getElementById('status');
    const progressBar = document.getElementById('progressBar');
    const textOutputDiv = document.getElementById('textOutput');
    const ttsAudio = document.getElementById('ttsAudio');
    const logDiv = document.getElementById('log');
    const apiKeyInput = document.getElementById('apiKeyInput');

    let localStream = null;
    let mediaRecorder = null;
    let recordedChunks = [];
    let pc = null;
    let dataChannel = null;
    let sessionId = null;
    let isRecording = false;

    function log(msg, type="info") {
      const color = type === "error" ? "red" : type === "status" ? "green" : "black";
      const time = new Date().toLocaleTimeString();
      logDiv.innerHTML = `<span style="color:${color}">[${time}] ${msg}</span><br>` + logDiv.innerHTML;
    }

    function updateStatus(msg, val=0) {
      statusDiv.textContent = msg;
      progressBar.value = val;
    }

    // ========================== INIT ==========================
    window.onload = async () => {
      try {
        localStream = await navigator.mediaDevices.getUserMedia({
            audio: { 
              echoCancellation: false,
              noiseSuppression: false,
              autoGainControl: false,
              channelCount: 1,
              sampleRate: 48000
            }
          });
        if (localStream.getAudioTracks().length > 0) {
          startBtn.disabled = false;
          updateStatus("‚úÖ Micro ƒë√£ s·∫µn s√†ng");
          log("üé§ Micro ƒë∆∞·ª£c c·∫•p quy·ªÅn th√†nh c√¥ng.");
        }
      } catch (err) {
        log("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o microphone: " + err.message, "error");
        updateStatus("Kh√¥ng th·ªÉ truy c·∫≠p microphone.");
      }
    };

    // ========================== RECORDING ==========================
    async function startRecording() {
      try {
    sessionId = crypto.randomUUID();
    recordedChunks = [];
    updateStatus("üéôÔ∏è Chu·∫©n b·ªã ghi √¢m...", 10);

    // === AUDIO WORKLET SETUP ===
    const audioContext = new AudioContext({ sampleRate: 48000 });
    await audioContext.audioWorklet.addModule("/static/audio-processor.js");


    // T·∫°o ngu·ªìn stream ‚Üí Worklet ‚Üí Destination
    let workletNode = null;
    let processedStream = null;

    function setupWorkletStream() {
      const source = audioContext.createMediaStreamSource(localStream);
      workletNode = new AudioWorkletNode(audioContext, "pcm-processor");

      processedStream = audioContext.createMediaStreamDestination();
      source.connect(workletNode);
      workletNode.connect(processedStream);
      workletNode.port.start();
      log("üîß AudioWorklet ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p.");
    }

        if (!localStream) {
          localStream = await navigator.mediaDevices.getUserMedia({
              audio: { 
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false,
                channelCount: 1,
                sampleRate: 48000
              }
            });;
        }

        const track = localStream.getAudioTracks()[0];
        if (!track || track.readyState !== "live") {
          log("‚ö†Ô∏è Mic ch∆∞a s·∫µn s√†ng, th·ª≠ l·∫°i sau...", "error");
          return;
        }
        setupWorkletStream(); 
        const mimeType = MediaRecorder.isTypeSupported("audio/wav")
          ? "audio/wav"
          : "audio/webm;codecs=opus";
        console.log("Worklet track =", processedStream.stream.getAudioTracks()[0]);

        mediaRecorder = new MediaRecorder(processedStream.stream, { mimeType });

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) recordedChunks.push(e.data);
        };

       //  mediaRecorder.onstop = async () => {
       //    const blob = new Blob(recordedChunks, { type: mimeType });
       //    const buffer = await blob.arrayBuffer();
       //    const view = new Int16Array(buffer);
       //    const rms = Math.sqrt(view.reduce((acc, val) => acc + val * val, 0) / (view.length || 1));
       //    log(`üéß RMS ghi ƒë∆∞·ª£c: ${rms.toFixed(4)}`, rms < 10 ? "error" : "status");

        //   const url = URL.createObjectURL(blob);
        //   const audio = document.createElement("audio");
        //   audio.src = url;
        //   audio.controls = true;
        //   document.body.appendChild(audio);
        //   log("üíæ L∆∞u file ghi √¢m c·ª•c b·ªô ho√†n t·∫•t.", "status");
        // };

        await new Promise(r => setTimeout(r, 1200));
        mediaRecorder.start(200);  // chunk m·ªói 200ms gi√∫p ·ªïn ƒë·ªãnh h∆°n

        isRecording = true;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        updateStatus("üî¥ ƒêang ghi √¢m...", 30);
        log("üéß MediaRecorder b·∫Øt ƒë·∫ßu ho·∫°t ƒë·ªông.", "status");

        pc = new RTCPeerConnection({ iceServers: [{ urls: "stun:stun.l.google.com:19302" }] });
        // === NEW: T√°ch 2 k√™nh DataChannel ===
        const pcmChannel = pc.createDataChannel("pcm");
        const controlChannel = pc.createDataChannel("control");

        controlChannel.onopen = () => console.log("[CONTROL] READY");
        pcmChannel.onopen = () => console.log("[PCM] READY");

        // G·ª≠i tr·ª±c ti·∫øp track mic sang backend, KH√îNG d√πng processedStream
        localStream.getAudioTracks().forEach(track => {
          const processedTrack = processedStream.stream.getAudioTracks()[0];
          pc.addTrack(processedTrack, processedStream.stream);
          log("üì° ƒê√£ g·ª≠i track t·ª´ AudioWorklet ‚Üí backend s·∫Ω nh·∫≠n PCM th·∫≠t.");
        });

        log("üì° ƒê√£ add tr·ª±c ti·∫øp audio track t·ª´ mic v√†o WebRTC.");

        pc.ontrack = (event) => {
          log("üì• WebRTC ƒëang g·ª≠i audio track sang backend...");
        };

        setInterval(() => {
                            const track = localStream.getAudioTracks()[0];
                            console.log("Mic status ‚Üí enabled:", track.enabled, "muted:", track.muted);
                          }, 1000);

        // KH√îNG STOP TRACK
        // localStream.getTracks().forEach(t => t.stop());
        dataChannel = pc.createDataChannel("ai_channel");

        dataChannel.onopen = () => {
          log("üì° DataChannel READY", "status");
          startBtn.disabled = false;
        };

        dataChannel.onmessage = handleDataChannelMessage;
        // G·ª≠i PCM t·ª´ worklet t·ªõi backend
        workletNode.port.onmessage = (event) => {
          if (dataChannel && dataChannel.readyState === "open") {
            dataChannel.send(event.data);
          }
        };


        const offer = await pc.createOffer({
            offerToReceiveAudio: true,
            offerToReceiveVideo: false
          });
        await pc.setLocalDescription(offer);
        const resp = await fetch("/offer", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            sdp: offer.sdp,
            type: offer.type,
            session_id: sessionId,
            api_key: apiKeyInput.value || "",
          }),
        });
        const answer = await resp.json();
        await pc.setRemoteDescription(answer);
      } catch (err) {
        log("‚ùå L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m: " + err.message, "error");
      }
    }

      function stopRecording() {
        try {
          if (mediaRecorder && mediaRecorder.state !== "inactive") {
            mediaRecorder.stop();
            log("üõë D·ª´ng ghi √¢m.", "status");
          }

          // üü£ G·ª¨I L·ªÜNH STOP WEBSOCKET ‚Üí BACKEND
          if (dataChannel && dataChannel.readyState === "open") {
            dataChannel.send(JSON.stringify({ type: "stop_recording" }));
            log("üì® G·ª≠i stop_recording qua DataChannel", "status");
          }

          updateStatus("‚è≥ ƒêang x·ª≠ l√Ω...", 80);
        } catch (err) {
          log("‚ùå L·ªói khi d·ª´ng ghi √¢m: " + err.message, "error");
        }
      }


    // ========================== HANDLE UPLOAD FILE ==========================
    uploadBtn.addEventListener("click", () => fileInput.click());

    fileInput.addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      if (!file.name.endsWith(".wav")) {
        log("‚ö†Ô∏è Ch·ªâ h·ªó tr·ª£ file WAV.", "error");
        return;
      }

      try {
        updateStatus("üì§ ƒêang g·ª≠i file WAV l√™n backend...", 40);
        const formData = new FormData();
        formData.append("file", file);
        formData.append("api_key", apiKeyInput.value || "");

        const resp = await fetch("/api/upload_wav", { method: "POST", body: formData });
        const result = await resp.json();

        if (result.error) {
          log("‚ùå L·ªói backend: " + result.error, "error");
        } else {
          log("‚úÖ File WAV ƒë√£ g·ª≠i th√†nh c√¥ng.");
          if (result.bot_text) {
            textOutputDiv.querySelector(".bot-text").innerHTML = `<strong>Bot:</strong> ${result.bot_text}`;
          }
          if (result.bot_audio_path) {
            ttsAudio.src = result.bot_audio_path;
            ttsAudio.load();
              ttsAudio.oncanplaythrough = () => ttsAudio.play();
          }
        }
        updateStatus("‚úÖ Ho√†n t·∫•t x·ª≠ l√Ω file WAV.", 100);
      } catch (err) {
        log("‚ùå L·ªói upload file WAV: " + err.message, "error");
        updateStatus("‚ùå Upload th·∫•t b·∫°i.", 0);
      }
    });

    // ========================== HANDLE MESSAGE ==========================
    function handleDataChannelMessage(e) {
  try {
    const data = JSON.parse(e.data);

    // --- TEXT STREAM ---
    if (data.type === "text_response_partial") {
      if (data.user_text) {
        textOutputDiv.querySelector(".user-text").innerHTML =
          `<strong>Ng∆∞·ªùi d√πng:</strong> ${data.user_text}`;
      }
      if (data.bot_text) {
        textOutputDiv.querySelector(".bot-text").innerHTML =
          `<strong>Bot:</strong> ${data.bot_text}`;
      }
      return;
    }

    // --- END SESSION: NH·∫¨N FILE WAV HO√ÄN CH·ªàNH ---
    if (data.type === "end_of_session") {
      const audioUrl = data.bot_audio_path;
      log("üéµ ƒêang t·∫£i file √¢m thanh ƒë·∫ßy ƒë·ªß: " + audioUrl);

      fetch(audioUrl)
        .then(res => res.blob())
        .then(blob => {
          const audioURL = URL.createObjectURL(blob);
          ttsAudio.src = audioURL;
          ttsAudio.load();

          ttsAudio.oncanplaythrough = () => {
            log("üîä Ph√°t file WAV ho√†n ch·ªânh");
            ttsAudio.play();
          };
        })
        .catch(err => log("‚ùå Audio load error: " + err.message, "error"));
    }

  } catch (err) {
    log("‚ö†Ô∏è L·ªói khi nh·∫≠n ph·∫£n h·ªìi: " + err.message, "error");
  }
}


    startBtn.onclick = startRecording;
    stopBtn.onclick = stopRecording;
  </script>
</body>
</html>
