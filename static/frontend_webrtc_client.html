<<<<<<< HEAD
<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice AI Assistant (WebRTC)</title>
  <style>
    body { font-family: Arial, sans-serif; background: #f4f6f9; margin: 0; padding: 20px; }
    .container { max-width: 860px; margin: auto; background: #fff; border-radius: 10px; padding: 20px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
    h1 { text-align: center; color: #333; margin-bottom: 10px; }
    .api-key-panel { background: #f8d7da; padding: 10px; border: 1px solid #f5c6cb; border-radius: 6px; }
    .control-panel { display: flex; justify-content: center; flex-wrap: wrap; gap: 15px; margin-top: 20px; }
    button { padding: 12px 24px; border-radius: 5px; border: none; font-size: 16px; cursor: pointer; }
    #startBtn { background: #28a745; color: white; }
    #stopBtn, #cancelBtn { background: #dc3545; color: white; }
    #uploadBtn { background: #007bff; color: white; }
    #status { text-align: center; margin-top: 15px; font-weight: bold; color: #007bff; }
    progress { width: 100%; height: 20px; margin-top: 8px; }
    .result-panel { margin-top: 20px; background: #fafafa; border: 1px solid #ddd; padding: 15px; border-radius: 6px; }
    .user-text { color: #333; margin-top: 10px; }
    .bot-text { color: #007bff; font-weight: bold; margin-top: 8px; }
    audio { width: 100%; margin-top: 10px; }
    #log { background: #f1f3f5; border-radius: 6px; padding: 10px; height: 200px; overflow-y: auto; font-size: 0.9em; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è Voice AI Assistant</h1>
    <div class="api-key-panel">
      <label for="apiKeyInput">üîê API Key: </label>
      <input id="apiKeyInput" type="text" placeholder="Nh·∫≠p API Key (t√πy ch·ªçn)" style="width:100%;">
    </div>

    <div class="control-panel">
      <button id="startBtn" disabled>üé§ Ghi √Çm</button>
      <button id="stopBtn" disabled>‚èπÔ∏è D·ª´ng</button>
      <button id="uploadBtn">üìÇ T·∫£i file WAV</button>
      <input type="file" id="fileInput" accept=".wav" style="display:none;">
      <button id="cancelBtn">‚ùå H·ªßy</button>
    </div>

    <div id="status">ƒêang kh·ªüi t·∫°o...</div>
    <progress id="progressBar" value="0" max="100"></progress>

    <div class="result-panel">
      <div id="textOutput">
        <div class="user-text"><strong>Ng∆∞·ªùi d√πng:</strong></div>
        <div class="bot-text"><strong>Bot:</strong></div>
      </div>
      <audio id="ttsAudio" controls autoplay></audio>
      <div id="log"></div>
    </div>
  </div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const uploadBtn = document.getElementById('uploadBtn');
    const fileInput = document.getElementById('fileInput');
    const cancelBtn = document.getElementById('cancelBtn');
    const statusDiv = document.getElementById('status');
    const progressBar = document.getElementById('progressBar');
    const textOutputDiv = document.getElementById('textOutput');
    const ttsAudio = document.getElementById('ttsAudio');
    const logDiv = document.getElementById('log');
    const apiKeyInput = document.getElementById('apiKeyInput');

    let localStream = null;
    let mediaRecorder = null;
    let recordedChunks = [];
    let pc = null;
    let dataChannel = null;
    let sessionId = null;
    let isRecording = false;

    function log(msg, type="info") {
      const color = type === "error" ? "red" : type === "status" ? "green" : "black";
      const time = new Date().toLocaleTimeString();
      logDiv.innerHTML = `<span style="color:${color}">[${time}] ${msg}</span><br>` + logDiv.innerHTML;
    }

    function updateStatus(msg, val=0) {
      statusDiv.textContent = msg;
      progressBar.value = val;
    }

    // ========================== INIT ==========================
    window.onload = async () => {
      try {
        localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        if (localStream.getAudioTracks().length > 0) {
          startBtn.disabled = false;
          updateStatus("‚úÖ Micro ƒë√£ s·∫µn s√†ng");
          log("üé§ Micro ƒë∆∞·ª£c c·∫•p quy·ªÅn th√†nh c√¥ng.");
        }
      } catch (err) {
        log("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o microphone: " + err.message, "error");
        updateStatus("Kh√¥ng th·ªÉ truy c·∫≠p microphone.");
      }
    };

    // ========================== RECORDING ==========================
    async function startRecording() {
      try {
        sessionId = crypto.randomUUID();
        recordedChunks = [];
        updateStatus("üéôÔ∏è Chu·∫©n b·ªã ghi √¢m...", 10);

        if (!localStream) {
          localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        }

        const track = localStream.getAudioTracks()[0];
        if (!track || track.readyState !== "live") {
          log("‚ö†Ô∏è Mic ch∆∞a s·∫µn s√†ng, th·ª≠ l·∫°i sau...", "error");
          return;
        }

        const mimeType = MediaRecorder.isTypeSupported("audio/wav")
          ? "audio/wav"
          : "audio/webm;codecs=opus";

        mediaRecorder = new MediaRecorder(localStream, { mimeType });

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) recordedChunks.push(e.data);
        };

        mediaRecorder.onstop = async () => {
          const blob = new Blob(recordedChunks, { type: mimeType });
          const buffer = await blob.arrayBuffer();
          const view = new Int16Array(buffer);
          const rms = Math.sqrt(view.reduce((acc, val) => acc + val * val, 0) / (view.length || 1));
          log(`üéß RMS ghi ƒë∆∞·ª£c: ${rms.toFixed(4)}`, rms < 10 ? "error" : "status");

          const url = URL.createObjectURL(blob);
          const audio = document.createElement("audio");
          audio.src = url;
          audio.controls = true;
          document.body.appendChild(audio);
          log("üíæ L∆∞u file ghi √¢m c·ª•c b·ªô ho√†n t·∫•t.", "status");
        };

        await new Promise(r => setTimeout(r, 500)); 
        mediaRecorder.start();
        isRecording = true;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        updateStatus("üî¥ ƒêang ghi √¢m...", 30);
        log("üéß MediaRecorder b·∫Øt ƒë·∫ßu ho·∫°t ƒë·ªông.", "status");

        pc = new RTCPeerConnection({ iceServers: [{ urls: "stun:stun.l.google.com:19302" }] });
        localStream.getTracks().forEach(track => pc.addTrack(track, localStream));
        dataChannel = pc.createDataChannel("ai_channel");
        dataChannel.onmessage = handleDataChannelMessage;

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        const resp = await fetch("/offer", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            sdp: offer.sdp,
            type: offer.type,
            session_id: sessionId,
            api_key: apiKeyInput.value || "",
          }),
        });
        const answer = await resp.json();
        await pc.setRemoteDescription(answer);
      } catch (err) {
        log("‚ùå L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m: " + err.message, "error");
      }
    }

    function stopRecording() {
      try {
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
          log("üõë D·ª´ng ghi √¢m.", "status");
        }
        if (localStream) localStream.getTracks().forEach(t => t.stop());
        updateStatus("‚è≥ ƒêang x·ª≠ l√Ω...", 80);
      } catch (err) {
        log("‚ùå L·ªói khi d·ª´ng ghi √¢m: " + err.message, "error");
      }
    }

    // ========================== HANDLE UPLOAD FILE ==========================
    uploadBtn.addEventListener("click", () => fileInput.click());

    fileInput.addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      if (!file.name.endsWith(".wav")) {
        log("‚ö†Ô∏è Ch·ªâ h·ªó tr·ª£ file WAV.", "error");
        return;
      }

      try {
        updateStatus("üì§ ƒêang g·ª≠i file WAV l√™n backend...", 40);
        const formData = new FormData();
        formData.append("file", file);
        formData.append("api_key", apiKeyInput.value || "");

        const resp = await fetch("/api/upload_wav", { method: "POST", body: formData });
        const result = await resp.json();

        if (result.error) {
          log("‚ùå L·ªói backend: " + result.error, "error");
        } else {
          log("‚úÖ File WAV ƒë√£ g·ª≠i th√†nh c√¥ng.");
          if (result.bot_text) {
            textOutputDiv.querySelector(".bot-text").innerHTML = `<strong>Bot:</strong> ${result.bot_text}`;
          }
          if (result.bot_audio_path) {
            ttsAudio.src = result.bot_audio_path;
            ttsAudio.play();
          }
        }
        updateStatus("‚úÖ Ho√†n t·∫•t x·ª≠ l√Ω file WAV.", 100);
      } catch (err) {
        log("‚ùå L·ªói upload file WAV: " + err.message, "error");
        updateStatus("‚ùå Upload th·∫•t b·∫°i.", 0);
      }
    });

    // ========================== HANDLE MESSAGE ==========================
    function handleDataChannelMessage(e) {
      try {
        const data = JSON.parse(e.data);
        if (data.user_text) {
          textOutputDiv.querySelector(".user-text").innerHTML = `<strong>Ng∆∞·ªùi d√πng:</strong> ${data.user_text}`;
        }
        if (data.bot_text) {
          textOutputDiv.querySelector(".bot-text").innerHTML = `<strong>Bot:</strong> ${data.bot_text}`;
        }
        if (data.bot_audio_path) {
          ttsAudio.src = data.bot_audio_path;
          ttsAudio.play();
        }
      } catch (err) {
        log("‚ö†Ô∏è L·ªói khi nh·∫≠n ph·∫£n h·ªìi: " + err.message, "error");
      }
    }

    startBtn.onclick = startRecording;
    stopBtn.onclick = stopRecording;
  </script>
</body>
</html>
=======
<!DOCTYPE html>
<html lang="vi">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice AI Assistant (WebRTC)</title>
  <style>
    body { font-family: Arial, sans-serif; background: #f4f6f9; margin: 0; padding: 20px; }
    .container { max-width: 860px; margin: auto; background: #fff; border-radius: 10px; padding: 20px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
    h1 { text-align: center; color: #333; margin-bottom: 10px; }
    .api-key-panel { background: #f8d7da; padding: 10px; border: 1px solid #f5c6cb; border-radius: 6px; }
    .control-panel { display: flex; justify-content: center; flex-wrap: wrap; gap: 15px; margin-top: 20px; }
    button { padding: 12px 24px; border-radius: 5px; border: none; font-size: 16px; cursor: pointer; }
    #startBtn { background: #28a745; color: white; }
    #stopBtn, #cancelBtn { background: #dc3545; color: white; }
    #uploadBtn { background: #007bff; color: white; }
    #status { text-align: center; margin-top: 15px; font-weight: bold; color: #007bff; }
    progress { width: 100%; height: 20px; margin-top: 8px; }
    .result-panel { margin-top: 20px; background: #fafafa; border: 1px solid #ddd; padding: 15px; border-radius: 6px; }
    .user-text { color: #333; margin-top: 10px; }
    .bot-text { color: #007bff; font-weight: bold; margin-top: 8px; }
    audio { width: 100%; margin-top: 10px; }
    #log { background: #f1f3f5; border-radius: 6px; padding: 10px; height: 200px; overflow-y: auto; font-size: 0.9em; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è Voice AI Assistant</h1>
    <div class="api-key-panel">
      <label for="apiKeyInput">üîê API Key: </label>
      <input id="apiKeyInput" type="text" placeholder="Nh·∫≠p API Key (t√πy ch·ªçn)" style="width:100%;">
    </div>

    <div class="control-panel">
      <button id="startBtn" disabled>üé§ Ghi √Çm</button>
      <button id="stopBtn" disabled>‚èπÔ∏è D·ª´ng</button>
      <button id="uploadBtn">üìÇ T·∫£i file WAV</button>
      <input type="file" id="fileInput" accept=".wav" style="display:none;">
      <button id="cancelBtn">‚ùå H·ªßy</button>
    </div>

    <div id="status">ƒêang kh·ªüi t·∫°o...</div>
    <progress id="progressBar" value="0" max="100"></progress>

    <div class="result-panel">
      <div id="textOutput">
        <div class="user-text"><strong>Ng∆∞·ªùi d√πng:</strong></div>
        <div class="bot-text"><strong>Bot:</strong></div>
      </div>
      <audio id="ttsAudio" controls autoplay></audio>
      <div id="log"></div>
    </div>
  </div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const uploadBtn = document.getElementById('uploadBtn');
    const fileInput = document.getElementById('fileInput');
    const cancelBtn = document.getElementById('cancelBtn');
    const statusDiv = document.getElementById('status');
    const progressBar = document.getElementById('progressBar');
    const textOutputDiv = document.getElementById('textOutput');
    const ttsAudio = document.getElementById('ttsAudio');
    const logDiv = document.getElementById('log');
    const apiKeyInput = document.getElementById('apiKeyInput');

    let localStream = null;
    let mediaRecorder = null;
    let recordedChunks = [];
    let pc = null;
    let dataChannel = null;
    let sessionId = null;
    let isRecording = false;

    function log(msg, type="info") {
      const color = type === "error" ? "red" : type === "status" ? "green" : "black";
      const time = new Date().toLocaleTimeString();
      logDiv.innerHTML = `<span style="color:${color}">[${time}] ${msg}</span><br>` + logDiv.innerHTML;
    }

    function updateStatus(msg, val=0) {
      statusDiv.textContent = msg;
      progressBar.value = val;
    }

    // ========================== INIT ==========================
    window.onload = async () => {
      try {
        localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        if (localStream.getAudioTracks().length > 0) {
          startBtn.disabled = false;
          updateStatus("‚úÖ Micro ƒë√£ s·∫µn s√†ng");
          log("üé§ Micro ƒë∆∞·ª£c c·∫•p quy·ªÅn th√†nh c√¥ng.");
        }
      } catch (err) {
        log("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o microphone: " + err.message, "error");
        updateStatus("Kh√¥ng th·ªÉ truy c·∫≠p microphone.");
      }
    };

    // ========================== RECORDING ==========================
    async function startRecording() {
      try {
        sessionId = crypto.randomUUID();
        recordedChunks = [];
        updateStatus("üéôÔ∏è Chu·∫©n b·ªã ghi √¢m...", 10);

        if (!localStream) {
          localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        }

        const track = localStream.getAudioTracks()[0];
        if (!track || track.readyState !== "live") {
          log("‚ö†Ô∏è Mic ch∆∞a s·∫µn s√†ng, th·ª≠ l·∫°i sau...", "error");
          return;
        }

        const mimeType = MediaRecorder.isTypeSupported("audio/wav")
          ? "audio/wav"
          : "audio/webm;codecs=opus";

        mediaRecorder = new MediaRecorder(localStream, { mimeType });

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) recordedChunks.push(e.data);
        };

        mediaRecorder.onstop = async () => {
          const blob = new Blob(recordedChunks, { type: mimeType });
          const buffer = await blob.arrayBuffer();
          const view = new Int16Array(buffer);
          const rms = Math.sqrt(view.reduce((acc, val) => acc + val * val, 0) / (view.length || 1));
          log(`üéß RMS ghi ƒë∆∞·ª£c: ${rms.toFixed(4)}`, rms < 10 ? "error" : "status");

          const url = URL.createObjectURL(blob);
          const audio = document.createElement("audio");
          audio.src = url;
          audio.controls = true;
          document.body.appendChild(audio);
          log("üíæ L∆∞u file ghi √¢m c·ª•c b·ªô ho√†n t·∫•t.", "status");
        };

        await new Promise(r => setTimeout(r, 500)); 
        mediaRecorder.start();
        isRecording = true;
        startBtn.disabled = true;
        stopBtn.disabled = false;
        updateStatus("üî¥ ƒêang ghi √¢m...", 30);
        log("üéß MediaRecorder b·∫Øt ƒë·∫ßu ho·∫°t ƒë·ªông.", "status");

        pc = new RTCPeerConnection({ iceServers: [{ urls: "stun:stun.l.google.com:19302" }] });
        localStream.getTracks().forEach(track => pc.addTrack(track, localStream));
        dataChannel = pc.createDataChannel("ai_channel");
        dataChannel.onmessage = handleDataChannelMessage;

        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        const resp = await fetch("/offer", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            sdp: offer.sdp,
            type: offer.type,
            session_id: sessionId,
            api_key: apiKeyInput.value || "",
          }),
        });
        const answer = await resp.json();
        await pc.setRemoteDescription(answer);
      } catch (err) {
        log("‚ùå L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m: " + err.message, "error");
      }
    }

    function stopRecording() {
      try {
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
          log("üõë D·ª´ng ghi √¢m.", "status");
        }
        if (localStream) localStream.getTracks().forEach(t => t.stop());
        updateStatus("‚è≥ ƒêang x·ª≠ l√Ω...", 80);
      } catch (err) {
        log("‚ùå L·ªói khi d·ª´ng ghi √¢m: " + err.message, "error");
      }
    }

    // ========================== HANDLE UPLOAD FILE ==========================
    uploadBtn.addEventListener("click", () => fileInput.click());

    fileInput.addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      if (!file.name.endsWith(".wav")) {
        log("‚ö†Ô∏è Ch·ªâ h·ªó tr·ª£ file WAV.", "error");
        return;
      }

      try {
        updateStatus("üì§ ƒêang g·ª≠i file WAV l√™n backend...", 40);
        const formData = new FormData();
        formData.append("file", file);
        formData.append("api_key", apiKeyInput.value || "");

        const resp = await fetch("/api/upload_wav", { method: "POST", body: formData });
        const result = await resp.json();

        if (result.error) {
          log("‚ùå L·ªói backend: " + result.error, "error");
        } else {
          log("‚úÖ File WAV ƒë√£ g·ª≠i th√†nh c√¥ng.");
          if (result.bot_text) {
            textOutputDiv.querySelector(".bot-text").innerHTML = `<strong>Bot:</strong> ${result.bot_text}`;
          }
          if (result.bot_audio_path) {
            ttsAudio.src = result.bot_audio_path;
            ttsAudio.play();
          }
        }
        updateStatus("‚úÖ Ho√†n t·∫•t x·ª≠ l√Ω file WAV.", 100);
      } catch (err) {
        log("‚ùå L·ªói upload file WAV: " + err.message, "error");
        updateStatus("‚ùå Upload th·∫•t b·∫°i.", 0);
      }
    });

    // ========================== HANDLE MESSAGE ==========================
    function handleDataChannelMessage(e) {
      try {
        const data = JSON.parse(e.data);
        if (data.user_text) {
          textOutputDiv.querySelector(".user-text").innerHTML = `<strong>Ng∆∞·ªùi d√πng:</strong> ${data.user_text}`;
        }
        if (data.bot_text) {
          textOutputDiv.querySelector(".bot-text").innerHTML = `<strong>Bot:</strong> ${data.bot_text}`;
        }
        if (data.bot_audio_path) {
          ttsAudio.src = data.bot_audio_path;
          ttsAudio.play();
        }
      } catch (err) {
        log("‚ö†Ô∏è L·ªói khi nh·∫≠n ph·∫£n h·ªìi: " + err.message, "error");
      }
    }

    startBtn.onclick = startRecording;
    stopBtn.onclick = stopRecording;
  </script>
</body>
</html>
>>>>>>> d957c982f899660a52cba8728118f4bbb190342c
