<!DOCTYPE html>
<html>
<head>
    <title>Voice AI Assistant (WebRTC)</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background-color: #f4f4f9; }
        .container { max-width: 800px; margin: auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
        h1 { color: #333; text-align: center; }
        .control-panel { display: flex; justify-content: space-around; margin-top: 20px; }
        button { padding: 10px 20px; font-size: 16px; cursor: pointer; border: none; border-radius: 5px; transition: background-color 0.3s; }
        #startBtn { background-color: #28a745; color: white; }
        #startBtn:disabled { background-color: #90ee90; cursor: not-allowed; }
        #startBtn:hover:not(:disabled) { background-color: #218838; }
        #stopBtn, #cancelBtn { background-color: #dc3545; color: white; }
        #stopBtn:hover, #cancelBtn:hover { background-color: #c82333; }
        #cancelBtn { display: none; }
        .result-panel { margin-top: 20px; padding: 15px; border: 1px solid #ccc; border-radius: 5px; background-color: #fff; }
        #log { margin-top: 15px; padding: 10px; background-color: #e9ecef; border-radius: 4px; max-height: 200px; overflow-y: auto; font-size: 0.9em; }
        #status { text-align: center; font-weight: bold; margin-top: 10px; color: #007bff; }
        #progressContainer { margin-top: 20px; }
        progress { width: 100%; height: 25px; }
        .text-output { margin-top: 10px; padding: 10px; border: 1px dashed #007bff; border-radius: 5px; }
        .user-text, .bot-text { margin-bottom: 5px; }
        .user-text { color: #343a40; }
        .bot-text { color: #007bff; font-weight: bold; }
        .api-key-panel { margin-top: 20px; padding: 10px; background-color: #f8d7da; border: 1px solid #f5c6cb; border-radius: 5px; }
        .audio-source-panel { margin-top: 20px; padding: 10px; border: 1px solid #ccc; border-radius: 5px; background-color: #f9f9f9; }
        .audio-source-panel label { margin-right: 15px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Voice AI Assistant (WebRTC)</h1>

        <div class="api-key-panel">
            <label for="apiKeyInput">API Key (Mocked for Demo):</label>
            <input type="text" id="apiKeyInput" placeholder="Nh·∫≠p API Key (Kh√¥ng b·∫Øt bu·ªôc trong demo n√†y)" style="width: 100%;">
        </div>

        <div class="audio-source-panel">
            <h2>Ch·ªçn ngu·ªìn Audio:</h2>
            <label><input type="radio" name="audioSource" value="mic" checked> Microphone</label>
            <label><input type="radio" name="audioSource" value="system"> √Çm thanh H·ªá th·ªëng (C·∫ßn Chia s·∫ª M√†n h√¨nh)</label>
        </div>

        <div class="control-panel">
            <button id="startBtn" disabled>‚ñ∂Ô∏è B·∫Øt ƒê·∫ßu Ghi √Çm</button>
            <button id="stopBtn" disabled>‚èπÔ∏è D·ª´ng & X·ª≠ L√Ω</button>
            <button id="cancelBtn">‚ùå H·ªßy X·ª≠ L√Ω</button>
        </div>

        <div id="status">ƒêang ch·ªù k·∫øt n·ªëi...</div>

        <div id="progressContainer">
            <progress id="progressBar" value="0" max="100"></progress>
        </div>

        <div class="result-panel">
            <h2>K·∫øt Qu·∫£:</h2>
            <div id="textOutput" class="text-output">
                <div class="user-text"><strong>Ng∆∞·ªùi d√πng:</strong> </div>
                <div class="bot-text"><strong>Bot:</strong> </div>
            </div>
            <audio id="ttsAudio" controls autoplay style="width: 100%; margin-top: 10px;"></audio>
            <div id="log"></div>
        </div>
    </div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const cancelBtn = document.getElementById('cancelBtn');
        const statusDiv = document.getElementById('status');
        const logDiv = document.getElementById('log');
        const textOutputDiv = document.getElementById('textOutput');
        const ttsAudio = document.getElementById('ttsAudio');
        const progressBar = document.getElementById('progressBar');
        const apiKeyInput = document.getElementById('apiKeyInput');
        
        // Ngu·ªìn Audio Selection
        const audioSourceRadios = document.querySelectorAll('input[name="audioSource"]');


        let pc = null;
        let dataChannel = null;
        let localStream = null;
        let sessionId = null;
        let ws = null;
        // C·ªù theo d√µi vi·ªác ƒë√£ c·ªë g·∫Øng l·∫•y quy·ªÅn Audio hay ch∆∞a
        let isPermissionAttempted = false; 

        // ======================================================
        // C√ÅC H√ÄM TI·ªÜN √çCH
        // ======================================================
        function log(message, type = 'info') {
            const time = new Date().toLocaleTimeString();
            logDiv.innerHTML = `<span style="color: ${type === 'error' ? 'red' : type === 'status' ? 'green' : 'black'};">[${time}] ${message}</span><br>` + logDiv.innerHTML;
        }

        function updateStatus(message, progressValue = 0) {
            statusDiv.textContent = message;
            progressBar.value = progressValue;
        }

        function resetUI(fullReset = false) {
            // C·∫≠p nh·∫≠t tr·∫°ng th√°i n√∫t Start d·ª±a tr√™n vi·ªác ƒë√£ c√≥ quy·ªÅn v√† stream hay ch∆∞a
            startBtn.disabled = !isPermissionAttempted || !localStream || localStream.getAudioTracks().length === 0;
            stopBtn.disabled = true;
            cancelBtn.style.display = 'none';
            if (fullReset) {
                 updateStatus('S·∫µn s√†ng cho phi√™n m·ªõi.', 0);
                 textOutputDiv.querySelector('.user-text').innerHTML = '<strong>Ng∆∞·ªùi d√πng:</strong> ';
                 textOutputDiv.querySelector('.bot-text').innerHTML = '<strong>Bot:</strong> ';
            }
        }

        // ======================================================
        // WEBSOCKET (cho ICE Candidates)
        // ======================================================
        function initWebSocket(pc, newSessionId) {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.close();
            }
            
            sessionId = newSessionId;
            const wsUrl = `ws://${window.location.host}/ws?session_id=${sessionId}`;
            ws = new WebSocket(wsUrl);

            ws.onopen = () => {
                log('WebSocket ƒë√£ k·∫øt n·ªëi th√†nh c√¥ng.', 'status');
                pc.onicecandidate = ({ candidate }) => {
                    if (candidate) {
                        log(`[WebRTC] Nh·∫≠n ICE Candidate: ${candidate.type}`);
                    } else {
                        log('[WebRTC] Ho√†n t·∫•t thu th·∫≠p ICE Candidates.');
                    }
                };
            };

            ws.onclose = () => {
                log('WebSocket ƒë√£ ƒë√≥ng.', 'status');
            };

            ws.onerror = (error) => {
                log(`L·ªói WebSocket: ${error}`, 'error');
            };
        }
        
        // ======================================================
        // PEER CONNECTION V√Ä SIGNALLING
        // ======================================================
        async function createPeerConnection() {
            if (!localStream || localStream.getAudioTracks().length === 0) {
                 log('‚ùå Kh√¥ng c√≥ lu·ªìng audio h·ª£p l·ªá ƒë·ªÉ b·∫Øt ƒë·∫ßu.', 'error');
                 alert('Kh√¥ng c√≥ lu·ªìng audio h·ª£p l·ªá ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m. Vui l√≤ng c·∫•p quy·ªÅn Microphone ho·∫∑c ch·ªçn √Çm thanh H·ªá th·ªëng.');
                 resetUI(true);
                 return;
            }

            if (pc && pc.connectionState !== 'closed') {
                try {
                    await pc.close();
                    log('[WebRTC] ƒê√£ ƒë√≥ng Peer Connection c≈©.');
                } catch (e) {
                     log(`[WebRTC] L·ªói khi ƒë√≥ng PC c≈©: ${e.message}`, 'error');
                }
            }
            
            sessionId = crypto.randomUUID();
            pc = new RTCPeerConnection();
            
            // 1. Kh·ªüi t·∫°o WebSocket cho phi√™n m·ªõi
            initWebSocket(pc, sessionId); 
            
            pc.onconnectionstatechange = () => {
                log(`[WebRTC] Tr·∫°ng th√°i k·∫øt n·ªëi: ${pc.connectionState}`);
                if (pc.connectionState === 'disconnected' || pc.connectionState === 'failed') {
                    log('[WebRTC] K·∫øt n·ªëi b·ªã ng·∫Øt ho·∫∑c th·∫•t b·∫°i.', 'error');
                    resetUI(true);
                } else if (pc.connectionState === 'closed') {
                     log('[WebRTC] K·∫øt n·ªëi ƒë√£ ƒë√≥ng.', 'status');
                     resetUI(true);
                }
            };

            // 2. Th√™m MediaStreamTrack (audio) t·ª´ microphone/h·ªá th·ªëng
            localStream.getTracks().forEach(track => {
                 pc.addTrack(track, localStream);
                 log(`[WebRTC] ƒê√£ th√™m track ${track.kind} v√†o Peer Connection.`);
            });
            
            // 3. T·∫°o Data Channel cho tin nh·∫Øn ƒëi·ªÅu khi·ªÉn
            dataChannel = pc.createDataChannel("chat");
            dataChannel.onopen = () => {
                log('[DataChannel] ƒê√£ m·ªü Data Channel.', 'status');
                startBtn.disabled = true;
                stopBtn.disabled = false;
                updateStatus('üîä ƒêang Ghi √Çm...', 5);
                cancelBtn.style.display = 'none'; // Ch·ªâ hi·ªÉn th·ªã khi ƒëang x·ª≠ l√Ω
            };

            dataChannel.onmessage = handleDataChannelMessage;
            dataChannel.onclose = () => log('[DataChannel] ƒê√£ ƒë√≥ng Data Channel.');

            // 4. T·∫°o Offer v√† g·ª≠i ƒë·∫øn Backend
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            
            updateStatus('ƒêang thi·∫øt l·∫≠p k·∫øt n·ªëi WebRTC...', 10);
            log(`[WebRTC] ƒê√£ g·ª≠i SDP Offer ƒë·∫øn Server. Session ID: ${sessionId}`);

            try {
                const response = await fetch('/offer', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        sdp: pc.localDescription.sdp,
                        type: pc.localDescription.type,
                        session_id: sessionId,
                        api_key: apiKeyInput.value.trim() 
                    })
                });
                
                if (!response.ok) throw new Error('Server returned non-ok status');

                const answer = await response.json();
                await pc.setRemoteDescription(new RTCSessionDescription(answer));
                updateStatus('ƒê√£ thi·∫øt l·∫≠p k·∫øt n·ªëi WebRTC. S·∫µn s√†ng ghi √¢m.', 20);

            } catch (e) {
                log(`L·ªói Signalling/Offer: ${e.message}`, 'error');
                updateStatus('‚ùå L·ªói k·∫øt n·ªëi Server.', 0);
                try { await pc.close(); } catch {}
                resetUI(true);
            }
        }
        
        function playFinalAudio(audioPath) {
            if (!audioPath) {
                 log('[TTS] ‚ùå Kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n audio ph·∫£n h·ªìi.', 'error');
                 resetUI(true);
                 return;
            }
            
            ttsAudio.src = audioPath;
            ttsAudio.load(); 

            // FIX L·ªñI AUTOPLAY: S·ª≠ d·ª•ng PlayPromise
            const playPromise = ttsAudio.play();
            
            if (playPromise !== undefined) {
                playPromise.then(_ => {
                    log('[TTS] ‚úÖ ƒêang ph√°t audio ph·∫£n h·ªìi...', 'status');
                }).catch(e => {
                    log(`‚ùå L·ªói khi ph√°t audio: ${e.message}. Tr√¨nh duy·ªát ƒë√£ ch·∫∑n Autoplay. Vui l√≤ng nh·∫•p chu·ªôt v√†o trang tr∆∞·ªõc khi th·ª≠ l·∫°i.`, 'error');
                    updateStatus('‚ùå B·ªã ch·∫∑n ph√°t. S·∫µn s√†ng cho phi√™n m·ªõi.', 100);
                    resetUI(true); 
                });
            } else {
                 log('[TTS] ‚úÖ ƒêang ph√°t audio ph·∫£n h·ªìi (Kh√¥ng c√≥ PlayPromise)...', 'status');
            }
        }


        function handleDataChannelMessage(event) {
            try {
                const data = JSON.parse(event.data);
                
                if (data.type === 'start_processing') {
                    updateStatus('üß† Server ƒëang X·ª≠ l√Ω ASR & NLU...', 40);
                    stopBtn.disabled = true;
                    cancelBtn.style.display = 'inline-block';
                    // ƒê·∫£m b·∫£o d·ª´ng ph√°t audio c≈© v√† x√≥a src ƒë·ªÉ kh√¥ng b·ªã xung ƒë·ªôt
                    ttsAudio.removeAttribute('src'); 
                    ttsAudio.pause();

                // üö® S·ª≠a: Nh·∫≠n k·∫øt qu·∫£ ASR/NLU s·ªõm (partial)
                } else if (data.type === 'text_response_partial') {
                    updateStatus('üéµ Server ƒëang T·ªïng h·ª£p TTS...', 70);
                    textOutputDiv.querySelector('.user-text').innerHTML = `<strong>Ng∆∞·ªùi d√πng:</strong> ${data.user_text || 'Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i.'}`;
                    textOutputDiv.querySelector('.bot-text').innerHTML = `<strong>Bot:</strong> ${data.bot_text}`;

                // üö® S·ª≠a: Nh·∫≠n t√≠n hi·ªáu k·∫øt th√∫c v√† ƒë∆∞·ªùng d·∫´n file
                } else if (data.type === 'end_of_session') {
                    updateStatus('‚úÖ X·ª≠ l√Ω ho√†n t·∫•t. ƒêang ph√°t audio...', 100);
                    if (data.bot_audio_path) {
                        log(`[TTS] ƒê√£ nh·∫≠n ƒë∆∞·ªùng d·∫´n file: ${data.bot_audio_path}`);
                        playFinalAudio(data.bot_audio_path); // Ch∆°i file t·ª´ ƒë∆∞·ªùng d·∫´n
                    } else {
                         log('[TTS] ‚ö†Ô∏è Ho√†n t·∫•t phi√™n nh∆∞ng kh√¥ng c√≥ file audio ph·∫£n h·ªìi.', 'warning');
                         resetUI(true);
                    }
                    
                } else if (data.type === 'error') {
                    log(`L·ªñI X·ª¨ L√ù SERVER: ${data.error}`, 'error');
                    updateStatus('‚ùå L·ªói Server. Vui l√≤ng th·ª≠ l·∫°i.', 0);
                    resetUI(true);
                }

            } catch (e) {
                log(`L·ªói ph√¢n t√≠ch JSON t·ª´ Data Channel: ${e.message}`, 'error');
            }
        }
        
        // ======================================================
        // C√ÅC H√ÄM ƒêI·ªÄU KHI·ªÇN
        // ======================================================
        async function stopRecording() {
            if (pc && pc.connectionState === 'connected') {
                updateStatus('ƒêang k·∫øt th√∫c ghi √¢m v√† g·ª≠i l·ªánh x·ª≠ l√Ω...', 30);
                stopBtn.disabled = true;
                startBtn.disabled = true; 
                
                // G·ª≠i l·ªánh D·ª™NG GHI √ÇM ƒë·∫øn Backend qua Data Channel
                if (dataChannel && dataChannel.readyState === 'open') {
                    dataChannel.send(JSON.stringify({ type: 'stop_recording' }));
                    log('[DataChannel] ƒê√£ g·ª≠i l·ªánh D·ª™NG GHI √ÇM.');
                }
            }
        }
        
        function sendCancelMessage() {
            if (pc && pc.connectionState === 'connected' && dataChannel && dataChannel.readyState === 'open') {
                dataChannel.send(JSON.stringify({ type: 'cancel_processing' }));
                log('[DataChannel] ƒê√£ g·ª≠i l·ªánh H·ª¶Y X·ª¨ L√ù.', 'error');
                updateStatus('ƒê√£ h·ªßy x·ª≠ l√Ω.', 0);
                
                if (ttsAudio.src) { 
                    ttsAudio.pause(); 
                    ttsAudio.removeAttribute('src'); 
                }
                
                resetUI(true);
            }
        }

        // ======================================================
        // KH·ªûI T·∫†O MICROPHONE/SYSTEM AUDIO (TR·∫¢ V·ªÄ BOOLEAN)
        // ======================================================
        async function initStream(force = false) {
            const selectedSource = document.querySelector('input[name="audioSource"]:checked').value;

            // N·∫øu stream ƒë√£ t·ªìn t·∫°i v√† ƒë√∫ng ngu·ªìn, kh√¥ng c·∫ßn kh·ªüi t·∫°o l·∫°i
            if (localStream && !force) {
                let isCorrectSource = false;
                const audioTrack = localStream.getAudioTracks()[0];
                if (audioTrack) {
                    const isMic = audioTrack.label.toLowerCase().includes('mic');
                    const isDisplay = audioTrack.label.toLowerCase().includes('display') || audioTrack.label.toLowerCase().includes('system');
                    
                    if (selectedSource === 'mic' && isMic) isCorrectSource = true;
                    if (selectedSource === 'system' && isDisplay) isCorrectSource = true;
                }
                if (isCorrectSource) {
                    isPermissionAttempted = true; 
                    return true;
                }
            }
            
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
                localStream = null;
            }

            try {
                if (selectedSource === 'mic') {
                    localStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                    log('‚úÖ Truy c·∫≠p Microphone th√†nh c√¥ng.', 'status');
                } else if (selectedSource === 'system') {
                    localStream = await navigator.mediaDevices.getDisplayMedia({ video: false, audio: true });
                    
                    const audioTrack = localStream.getAudioTracks()[0];
                    if (audioTrack) {
                         audioTrack.onended = () => {
                            log('‚ö†Ô∏è Chia s·∫ª √Çm thanh H·ªá th·ªëng ƒë√£ b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng/tr√¨nh duy·ªát.', 'error');
                            if (pc && pc.connectionState !== 'closed') {
                                stopRecording(); 
                            }
                        };
                        log('‚úÖ Truy c·∫≠p √Çm thanh H·ªá th·ªëng th√†nh c√¥ng (Vui l√≤ng ch·ªçn "Chia s·∫ª √¢m thanh" trong h·ªôp tho·∫°i).', 'status');
                    } else {
                        log('‚ùå L·ªói: Kh√¥ng th·ªÉ l·∫•y lu·ªìng Audio t·ª´ Chia s·∫ª M√†n h√¨nh. H√£y ƒë·∫£m b·∫£o ch·ªçn "Chia s·∫ª √¢m thanh".', 'error');
                        localStream.getTracks().forEach(track => track.stop());
                        localStream = null;
                    }
                }
                
                isPermissionAttempted = true;
                return localStream && localStream.getAudioTracks().length > 0;

            } catch (e) {
                log(`‚ùå L·ªói truy c·∫≠p Audio (${selectedSource}): ${e.name}: ${e.message}`, 'error');
                isPermissionAttempted = true; 
                return false;
            }
        }
        
        // H√†m x·ª≠ l√Ω t∆∞∆°ng t√°c ƒë·∫ßu ti√™n ƒë·ªÉ y√™u c·∫ßu quy·ªÅn
        async function requestPermissionOnFirstInteraction() {
            // Lo·∫°i b·ªè Listener ƒë·ªÉ ch·ªâ ch·∫°y m·ªôt l·∫ßn duy nh·∫•t
            document.body.removeEventListener('click', requestPermissionOnFirstInteraction);
            document.body.removeEventListener('touchstart', requestPermissionOnFirstInteraction);
            
            await handlePermissionRequest();
        }
        
        // Logic request quy·ªÅn ƒë·ªôc l·∫≠p
        async function handlePermissionRequest() {
            // N·∫øu ƒë√£ c√≥ stream, kh√¥ng c·∫ßn y√™u c·∫ßu l·∫°i
            if (localStream && localStream.getAudioTracks().length > 0) return true;

            updateStatus('ƒêang y√™u c·∫ßu c·∫•p quy·ªÅn Audio...', 0);
            const success = await initStream(true); 
            
            if (success) {
                updateStatus('‚úÖ Quy·ªÅn Audio ƒë√£ ƒë∆∞·ª£c c·∫•p. S·∫µn s√†ng b·∫Øt ƒë·∫ßu.', 0);
                startBtn.disabled = false;
                return true;
            } else {
                updateStatus('‚ö†Ô∏è L·ªói/T·ª´ ch·ªëi c·∫•p quy·ªÅn Audio. Vui l√≤ng nh·∫•p l·∫°i START.', 0);
                startBtn.disabled = true;
                return false;
            }
        }

        // ======================================================
        // EVENT LISTENERS
        // ======================================================
        startBtn.addEventListener('click', async () => {
             // 1. N·∫øu ch∆∞a c√≥ stream (ch∆∞a c·∫•p quy·ªÅn), y√™u c·∫ßu quy·ªÅn tr∆∞·ªõc
             if (!localStream || localStream.getAudioTracks().length === 0) {
                 const success = await handlePermissionRequest();
                 if (!success) {
                     log('‚ùå Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu do kh√¥ng c√≥ quy·ªÅn Audio.', 'error');
                     return;
                 }
             }
             
             // 2. B·∫Øt ƒë·∫ßu Peer Connection
             createPeerConnection(); 
        });
        
        audioSourceRadios.forEach(radio => {
            radio.addEventListener('change', () => {
                 // N·∫øu ƒë√£ c√≥ quy·ªÅn, initStream l·∫°i ƒë·ªÉ chuy·ªÉn ngu·ªìn.
                if (isPermissionAttempted) {
                    handlePermissionRequest(); 
                }
            });
        });
        
        stopBtn.addEventListener('click', stopRecording); 

        cancelBtn.addEventListener('click', sendCancelMessage);
        
        ttsAudio.onended = () => {
             log('[TTS] K·∫øt th√∫c ph√°t audio.', 'status');
             updateStatus('ƒê√£ x·ª≠ l√Ω xong. S·∫µn s√†ng cho phi√™n m·ªõi.', 100);
             
             ttsAudio.removeAttribute('src'); 
             
             resetUI(true); 
        }
        
        ttsAudio.onerror = (e) => {
             // L·ªói n√†y b·∫Øt l·ªói Failed to load because no supported source was found.
             log(`‚ùå L·ªói t·∫£i audio (Code: ${e.target.error.code}): URL audio c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá.`, 'error');
             
             ttsAudio.removeAttribute('src'); 

             updateStatus('‚ùå L·ªói t·∫£i audio ph·∫£n h·ªìi.', 0);
             resetUI(true);
        }


        window.onload = function() {
            // Load API Key
            const savedKey = localStorage.getItem('voice_ai_api_key');
            if (savedKey) {
                apiKeyInput.value = savedKey;
            } 
            
            // Thi·∫øt l·∫≠p Listener cho t∆∞∆°ng t√°c ƒë·∫ßu ti√™n
            document.body.addEventListener('click', requestPermissionOnFirstInteraction, { once: true });
            document.body.addEventListener('touchstart', requestPermissionOnFirstInteraction, { once: true });
            
            // Tr·∫°ng th√°i ch·ªù t∆∞∆°ng t√°c
            startBtn.disabled = true;
            updateStatus('Vui l√≤ng nh·∫•p v√†o b·∫•t k·ª≥ ƒë√¢u tr√™n trang ho·∫∑c n√∫t START ƒë·ªÉ c·∫•p quy·ªÅn Audio...');
        };

        apiKeyInput.addEventListener('change', () => {
            const key = apiKeyInput.value.trim();
            localStorage.setItem('voice_ai_api_key', key);
            log("API Key ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°m th·ªùi.", 'status');
        });
        
        if (!navigator.mediaDevices || !RTCPeerConnection) {
            alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ WebRTC.");
        }

    </script>
</body>
</html>